\documentclass[declaration,shortabstract]{iithesis}

\usepackage[utf8]{inputenc}

\polishtitle{Efekty koalgebraiczne oraz ich kohandlery \fmlinebreak{} w językach programowania}
\englishtitle{Coalgebraic effects and their cohandlers \fmlinebreak{} in programming languages}
\polishabstract{
    Efekty algebraiczne są dobrym rozwiązaniem na modelowanie efektów
    obliczeniowych, w sposób który dobrze się składa. Niemniej, powstają przy
    nich problemy z idiomatycznym zarządzaniem zasobami. Z matematycznej
    strony, tworzą one wolne modele nad teoriami algebraicznymi, a ich handlery
    homomorfizmy zachowujące strukturę modelu. Dualnym pojęciem są komodele,
    które okazały się odpowiednim narzędziem do wyrażania w kodzie przejść z
    przekazywaniem stanu. Prezentujemy rachunek z efektami algebraicznymi i
    koalgebraicznymi, aby zaadresować problemy z zarządzaniem zewnętrznym stanem.
}
\englishabstract{
    Algebraic effects are a great way to model computational effects in a
    composable way. Nonetheless, they give rise to issues with idiomatic
    resource management. From mathematical side, they form
    free models over algebraic theories, with handlers being homomorphisms
    preserving the model structure. Dualizing this notion gives us comodels,
    which turned out to be suitable for expressing state-passing transitions
    in the code. We present a calculus with algebraic and coalgebraic effects,
    to address the issues with external state management and provide abstraction
    over resources.
}
\author{Mateusz Urbańczyk}
\advisor{dr Maciej Piróg}
\date{1 września 2020}                     % Data zlozenia pracy
% Dane do oswiadczenia o autorskim wykonaniu
\transcriptnum{291480}                     % Numer indeksu
\advisorgen{dr. Macieja Piróga} % Nazwisko promotora w dopelniaczu
%%%%%

% \usepackage[utf8]{inputenc}
% \usepackage{graphicx,listings,tikz}
\usepackage{syntax}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{mathalfa}
\usepackage{textcomp}
\usepackage{stmaryrd}
\usepackage{bussproofs}
\usepackage{tikz-cd}
\usepackage{fancyvrb}
\usetikzlibrary{babel}

% Disable certain warnings
% chktex-file 18
% chktex-file 36

\usepackage[backend=bibtex]{biblatex}
\addbibresource{mybib.bib}

\theoremstyle{definition} \newtheorem{definition}{Definition}[chapter]
\theoremstyle{remark} \newtheorem{remark}[definition]{Observation}
\theoremstyle{plain} \newtheorem{theorem}[definition]{Theorem}
\theoremstyle{plain} \newtheorem{lemma}[definition]{Lemma}
%\renewcommand \qedsymbol {\ensuremath{\square}}

\newcommand{\mathVar}[1]{{\operatorname{\mathit{#1}}}}

\begin{document}

\chapter{Introduction}\label{chapter:introduction}

\textit{
    My algebraic methods are really methods of working and thinking; this is why
    they have crept in everywhere anonymously. $\sim{}$Emmy Noether
}

In this thesis we discuss issues arising from combining algebraic effects
and handlers with resource management, and present a solution through coalgebraic
means along with presentation of experimental programming language Freak, which
is a language with (co)algebraic effects and (co)handlers, where implementation
is based on Continuation Passing Style translation.

\section{Problem Statement}\label{sec:problem-statement}

Algebraic effects, while not a new concept, have received a lot of
attention~\cite{effects-bibliography} in recent years, both from the theoretical
and practical side.

They give the developer necessary tools for declarative programming with
computational effects on a high level of abstraction, by defining
effects as an API\@ in the code. At the same time, algebraic effects preserve
a lot of flexibility and have a strong theoretical foundations.

In fact, that very flexibility can be troublesome. Allowing developer for too
much freedom may lead to undesired behaviour and incorrect programs.

In particular, multi-shot resumptions in effect handlers and the possibility to
drop the resumption allow one to express fairly complex logic in a concise way,
but at the same time, they give rise to issues that would not occur in standard
control flow, especially when composing various effects together. Unwanted
interaction with external resources multiple times or not invoking finalisation
code are cases that may occur while using algebraic effects and handlers. Let's
consider the following example:

\vbox{\begin{verbatim}
    handle
        let fh <- do Open "praise.txt" in
        let c <- do Choice () in
        let text <- if c then return "Guy Fieri" else return "is cool" in
        let _ <- do Write (fh, text) in
        do Close fh
    with {
        Choose _ k ->
            let t <- r 1 in
            let f <- r 0 in
            return (t, f) |
        return x -> return x
    }
\end{verbatim}
}

In the above code we open file, and based on nondeterministic choice, we write
to the file, and then close it. This piece of code looks harmless, however, as
we invoke resumption for the second time, we are attempting to write to the
closed file, and then close it once again. In fact, dropping resumption is also
considered harmful, as we would not attempt to close the file.

This captures the excessive generality of effects, and is the issue that we
would like to address with coalgebraic effects.

\section{Thesis Outline}


In the following chapter we provide a background about effects, define algebraic
effects in the categorical setting as well as point out dual coalgebraic effects
and cohandlers, finishing with showing related work in this area.
Chapter~\ref{chapter:potential-solutions} describes possible ways to approach
the issue of excessive generality, Chapter~\ref{chapter:co-effectful-programming}
shows the Freak language by examples along with a usage guide, and then
Chapter~\ref{chapter:calculus-of-freak-language} describes the language's syntax,
operational semantics and CPS translation. In the next one,
Chapter~\ref{chapter:implementation}, implementation details are revealed.
We conclude in Chapter~\ref{chapter:conclusion} by stating what the possible
augmentations are, which are intended to be made in the future.

\chapter{Background}\label{chapter:background}

\section{Computational Effects}

Since the rapid development of computational theory in 1930s by A. Turing,
K. Godel and A. Church, we have a well-established notion of what can and what
cannot be done through algorithmic means, which we can almost directly translate
to being computable by our machines. Through next years we have developed
mainstream languages that are used almost everywhere, with great success.

Under these circumstances one may pose a question, why do we still bother with
development of languages theory, since so much has been done already. Is there
anything that drives us towards further research? Indeed, one active branch
revolves around equational theory to assess equality of two programs, which we
know that in the general setting is undecidable. Proof methods may include
extensional, contextual or logical equality. However, there is no doubt that
these formal ways of reasoning about programs, while being crucial for assessing
correctness, do not bring direct benefits for everyday use cases, as they are
rarely accessible by a common developer.

Other branch of languages theory, that we shall investigate more in this thesis,
is about taming complexity of programs. Various methods of static analysis has
been developed for various use cases, most notably, type systems. Thanks to strong
and static type systems along with their implementations, we have solid tools to
work efficiently on functions that are pure. That being said, we claim that the
core complexity of programs comes from side effects, or more generally, computational
effects, which we cannot avoid in writing anything useful.

We need to have a good way for handling computational effects. One of the ways
to model them, can be done through monads~\cite{monads-wadler, moggi}. However,
they were found to be, to say the least, cumbersome to work with when the number
of different effects increase. It is perhaps not a coincidence that many
functional programming languages do not have them, because of the non-composable
nature of them, or at least not composable in their implementations.

\noindent
Let's put the following functions

\begin{center}

    $ f: a \rightarrow b $, $ g : b \rightarrow c $ \\
    $ f': a \rightarrow m \; b $, $ g' : b \rightarrow m \; c $ \\
    $ f'': a \rightarrow m' \; m \; b $, $ g'' : b \rightarrow m' \; m \; c $ \\

\end{center}

\noindent
where $m$, $m'$ are monads. Functions $f$, $g$ can be composed using standard
composition, for $f'$, $g'$ we can use Kleisli composition operator from monad $m$.
What in case of adding one more effect, $f''$ and $g''$?

It turns out, that it becomes complex and unpleasant to combine two functors
together to form a new monad, and for this purpose, monad
transformers~\cite{monad-transformers} arose in Haskell. Most of the common
languages avoid this by not expressing computational effects in the type system,
and instead one may think about functions as being implicitly embed in a Kleisli
Category over a functor T~\cite{kleisli-ncatlab}, where T is a hidden signature
over all possible side effects that occur in our program.

\noindent
TODO Reconsider reference to ncatlab on Kleisli Cat, often it's not the best resource

Not only we would like to bring back effects to our type
system~\cite{type-and-effect}, but also do it in a way that is composable. This
is where algebraic effects comes to the rescue. From theoretical point of view,
we need to develop equational theory about our effects to assert correctness of
our language as well as to have the right hammer to reason about our programs.
From practical side, we need to have the way of taming computational effects
in our programs. That is the point where we would like to introduce to unfamiliar
readers a notion of algebraic effects.

\section{Algebraic Effects}

Algebraic effects can be thought of as an public interface for computational effects.
Declarative approach allow us to write programs in which the actual semantic of
source code is dependent on handler that defines the meaning of a subset of effects.

This is really an incredible feature from practical point of view, as we may substitute
logic depending on the execution environment. As an example, fetching for resources
can behave differently as we run tests, debug our code, or run it on production.
In the same manner, they neatly allow us to abstract over implementation details.

Patterns like these are well known in programming, for which other alternatives
arose. One can mention interfaces from object-oriented programming, which are also
a way to describe the API of a certain component. In order to abstract from
implementation details, we pass an object around which represents a certain
interface. While this is certainly better than having no abstractions at all,
we need to pass this interface into every function that is going to use it.
This practice is called dependency injection, and while it sounds like it solves
some of the issues, we end up in functions that need to carry representants
of the interfaces, and pass them in every subcall that they make.

That being said, it's only one particular issue that algebraic effects address.
Their handlers may also drop the resumption or invoke it more than
once. There are many other great sources for getting familiarized with
effects from practical side~\cite{handlers-tutorial, programming-in-eff, koka-tutorial},
so we will omit further explanations. More examples can be found in
Chapter~\ref{chapter:co-effectful-programming}.

\section{Categorical Setting of Universal Algebra}

Algebraic effects can be described via operational means, however,
for the purpose of presenting the duality between algebra and coalgebra,
we allow ourselves to wander a bit deeper into category theory and describe
effects from denotational point of view~\cite{bauer-what-is-algebraic}.

    \subsection{Algebraic Theories}

    % == begin Signature ==
    \begin{definition}

    A \textit{signature $ \Sigma $} is given by a collection of operation
    symbols $ op_{i} $ with associated parameters $ P_{i} $ and arities $ A_{i} $,
    where $ P_{i} $ and $ A_{i} $ are objects in the category of our interest.
    We will write an operation as $ op_{i} : P_{i} \rightsquigarrow A_{i} $

    \end{definition}
    % == end Signature ==

    % == begin Sigma-terms ==
    \begin{definition}
    Collection of $\mathVar{\Sigma-terms}$ is a free algebra with a generator $X$
    for a functor $ \mu H_{\Sigma} $ that maps objects into trees over a given
    signature $ \Sigma $ and morphisms into folds over trees.

    \end{definition}
    % == end Sigma-terms ==

    % == begin Sigma-equation ==
    \begin{definition}

        A $ \mathVar{\Sigma-Equation} $ is an object X and a pair of
        $\mathVar{\Sigma-terms}$ $l, r \in Tree_{\Sigma}(X)$, written as

        \begin{center}
        $ X \mid l = r $
        \end{center}

    \end{definition}
    % == end Sigma-equation ==

    % == begin Algebraic Theory ==
    \begin{definition}

    An \textit{algebraic theory} $T = (\Sigma_{T}, \mathcal{E}_{T})$, is given
    by a signature $\Sigma_{T}$ and a collection $\mathcal{E}_{T}$ of
    $\mathVar{\Sigma_{T}-equations}$. We might omit $T$ subscripts in case
    our theory of interest is obvious.

    \end{definition}
    % == end Algebraic Theory ==

    % == begin Interpretation ==
    \begin{definition}

    An \textit{interpretation $I$ over a given signature $\Sigma$} is given by
    a carrier object $|I|$ and for each $ op_{i} : P_{i} \rightsquigarrow A_{i} $
    in $\Sigma$ a map

    \begin{center}
        $ {\llbracket op_{i} \rrbracket}_I : P_{i} \times{} {|I|}^{A_{i}} \rightarrow |I| $
    \end{center}

    \noindent
    Interpretation may be naturally extended to $\mathVar{\Sigma-terms}$, such
    that a given $\mathVar{\Sigma-term}$ $X \mid t$ is interpreted by a map
    which sends variables into projections from environment and terms into
    map composition over each subterm.

    \end{definition}
    % == end Interpretation ==

    % == begin Model ==
    \begin{definition}

    A \textit{model M} of an algebraic theory T is an interpretation of the
    signature ${\Sigma_{T}}$ which validates all the equations $\mathcal{E_{T}}$.
    That is, for every equation $X \mid l = r$ the following diagram commutes:

    \begin{center}
    \begin{tikzcd}[row sep=huge, column sep=large]
        {|M|}^k \arrow[rr, "\llbracket{} X|r \rrbracket{}"', bend right] \arrow[rr, "\llbracket{} X|l \rrbracket{}", bend left] &  & {|M|}
    \end{tikzcd}
    \end{center}

    \end{definition}
    % == end Model ==

    % == begin homomophism ==
    \begin{definition}

    Let L, M be models of a theory T. $ \mathVar{T-homomorphism}$
    $\varphi : L \rightarrow M$ is a map such that, for every operation symbol
    $op_{i}$ in T the following diagram commutes:

    \begin{center}
    \begin{tikzcd}
        {|L|}^{ar_{i}} \arrow[rr, "{\llbracket{} op_{i} \rrbracket{}}_{L}"] \arrow[dd, "\varphi{}^{ar_{i}}"'] &  & {|L|} \arrow[dd, "\varphi{}"] \\
                                              &  &                                     \\
        {|M|}^{ar_{i}} \arrow[rr, "{\llbracket{} op_{i} \rrbracket{}}_{M}"']                 &  & {|M|}
    \end{tikzcd}
    \end{center}

    \noindent
    We denote here $A^{n}$ as $\mathVar{n-ary}$ product of $A$.

    \end{definition}
    % == end homomophism ==


    % == begin Free algebra ==
    \begin{definition}

    Free F-algebra on an object A (of generators) in $\mathcal{C}$ is meant an algebra

    \begin{center}

    $ \varphi_{A} : F A^{\#} \longrightarrow A $

    \end{center}

    \noindent
    together with an universal arrow $ \eta_{A} : A \longrightarrow A^{\#} $.
    Universality means that for every algebra $ \beta : F B \longrightarrow B $
    and every morphism $ f : A \longrightarrow B $ in $ \mathcal{C}$, there
    exists a unique homomorphism $ \overline{f} : A^{\#} \longrightarrow B $
    extending f, i.e.\ a unique morphism of $ \mathcal{C}$ for which the diagram
    below commutes:

    \begin{center}
    \begin{tikzcd}[row sep=huge, column sep=large]
    F A^{\#} \arrow[d, "F \overline{f}"] \arrow[r, "\varphi_{A}"] & A^{\#} \arrow[d, "\overline{f}"] & A \arrow[l, "\eta_{A}"'] \arrow[ld, "f"] \\
    F B \arrow[r, "\beta"']                                       & B                                &
    \end{tikzcd}
    \end{center}

    \end{definition}
    % == end Free algebra ==

    \begin{definition} \textit{Free model} is just a model that is free algebra.
    \end{definition}

    \begin{lemma}{Free models form monads}
    \end{lemma}
    \begin{proof}
        Let $M$ be a free model of an algebraic theory $T$ in category $\mathcal{C}$. We
        have an endofunctor $ F_{T}$, which takes objects into free model and
        maps to unique homomorphisms for which the following diagram commutes:

        \begin{center}
        \begin{tikzcd}
        X \arrow[rr, "\eta_{X}"] \arrow[dd, "f"'] &  & F_{T} (X) \arrow[dd, "\overline{f}"] \\
                                                  &  &                                     \\
        Y \arrow[rr, "\eta_{Y}"']                 &  & F_{T} (Y)
        \end{tikzcd}
        \end{center}

        \noindent
        which immediately gives us $\eta$ natural transformation for a monad.
        We can now define $\mu{}$ for a monad as a unique morphism for which
        the diagram commutes:

        \begin{center}
        \begin{tikzcd}[row sep=huge, column sep=large]
            F_{T} (X) \arrow[r, "\eta_{F_{T} (X)}"] \arrow[rd, "id"'] & F_{T} (F_{T} (X)) \arrow[d, "\mu{}"] \\
                                                         & F_{T} (Y)
        \end{tikzcd}
        \end{center}

        \noindent
        $F_{T}$ is an endofunctor, therefore it sends $X$ into an object in $\mathcal{C}$.
        From any object we have a unique map sending an object into model,
        which is $\eta_{F_{T} (X)}$. From free property of our model we get
        a unique map $\mu{}$ such that the diagram commutes, therefore we have
        a monad $(F_{T}, \eta{}, \mu{})$.

    \end{proof}


    % == begin handler ==
    \begin{definition} \textit{Handler} is a $\mathVar{T-homomorphism}$ between
    free models

        \begin{center}
        $ H : {| F_{T} (X) |} \rightarrow {| F_{T'} (X') |} $
        \end{center}

    \noindent
    that is, a map between carriers that preserves the structure of theory $T$.

    \end{definition}
    % == end handler ==

Concluding from the theory that we have built, algebraic effects are just free
models over computation trees, where the signature is the set of effects, and
equational theory is definining rules of rewriting expressions with effects.
The latter is usually irrelevant from implementation perspective, but may be
important for reasoning about programs.

Effect handlers on the other hand, are transformations from one computation
tree over given signature of effects into another one, where handler may serve
effects and also propagate new ones.

\section{Duality}\label{sec:duality}
    \subsection{Comodels}

    \begin{definition}
        Comodel in $\mathcal{C}$ is just a Model in $ \mathcal{C}^{op} $.
    \end{definition}

    We could end by stating this definition of comodels~\cite{comodels}, and
    everything else would follow directly from duality. However, expanding
    definitions is going to give us better intuition, as well as give more solid
    ground for implementation. For this part, we are going to assume we operate
    in \textbf{Set} category.

    \subsection{Cooperations}

    We have defined interpretation of an operation as a morphism:

    \begin{center}
        {$\displaystyle {\llbracket op \rrbracket}_M : P \times {|I|}^{A} \rightarrow |I| $}
    \end{center}

    \noindent
    following now straight from Yoneda Lemma, we have:

    \begin{center}
        {$\displaystyle {\llbracket op \rrbracket}_M : {|I|}^{A} \rightarrow |I|^{P} $}
    \end{center}

    Let's now take a look on how it dualizes. Since we operate in \textbf{Set},
    we can represent $A^{B}$ exponentials as $\mathVar{B-ary}$ products over $A$,
    where for each argument we select one result:

    \begin{center}
        {$\displaystyle {\llbracket op \rrbracket}_M : \prod_{a \in A}{|I|} \rightarrow \prod_{p \in P}{|I|} $}
    \end{center}

    % TODO: textbf Set^op
    \noindent
    We want now to embed this morphism in $Set^{op}$. Every arrow in opposite
    category is reverted, thus, products become coproducts and our morphism
    is reverted:

    \begin{center}
        {$\displaystyle {\llbracket op \rrbracket}_M : \coprod_{p \in P}{|I|} \rightarrow \coprod_{a \in A}{|I|} $}
    \end{center}

    \noindent
    It turnes out, that this map can be further simplified.

    \begin{lemma}
        In \textbf{Set} category, the following isomorphism holds
        {$\displaystyle \coprod_{b \in B}{A} \cong B \times A $}
    \end{lemma}
    \begin{proof}
        We can think about $\mathVar{B-ary}$ coproducts (tagged unions) over the same set
        such that we have $B$ replicas of $A$ and we select which replica do we want
        to pick. Putting it this way, it immediately follows that it's the same,
        up to isomorphism, as a cartesian product over indexes from $B$ and
        corresponding $A$ sets. For a more detailed and generalized results,
        see~\cite{tensors}.
    \end{proof}

    Model turns into comodel~\cite{comodels}, which we shall also call \textit{world}.
    Putting this together with the above lemma, we obtain the following map:

    \begin{center}
        $ {\llbracket op \rrbracket}^W : {|I|} \times {P} \rightarrow  {|I|} \times {A} $
    \end{center}

    \noindent
    which is called a \textit{cooperation}. Meaning of that morphism, is that
    based on coalgebra carrier and a parameter, we obtain new state of the
    coalgebra and a value generated by coalgebra. This state-alike result that
    we have obtained by dualizing models is indeed surprising, and it's
    expected that reader may feel astonished after seeing it for the first time.
    This observation was made in~\cite{tensors}.

    \subsection{Coalgebraic Effects}

    We have now derived a dual concept to algebraic effects and handlers, which
    in the literature are also called comodels and runners~\cite{runners-uustalu, runners-in-action}.
    As we have seen, comodels turned into state-passing (co)operations, which
    in programming langauges, may be a way to model interaction with external
    resources, where based on current configuration and some parameter, we
    obtain new configuration along with it's result.

    \subsection{Coinductive Reasoning}

    Induction is a way of constructing new structures. Recursion is a way of
    folding inductively defined structure in a terminating way. Recursive
    functions (not to be confused with recursive computability class), should
    shrink the argument in each call, meaning that it eventually ends up
    terminating in a base case.

    Coinduction is literally a dual notion to induction. We \textit{observe} possibly
    infinite structures, by doing deconstruction. Corecursion, is a way
    of productively defining new, possibly enlarged structures. Due to infinity,
    the evaluation should be lazy, whereas in induction it may be eager.

    Here is a table that summarizes difference between these two methods of reasoning:

    \begin{center}
    \begin{tabular}{lcc}
    \toprule

    \textbf{feature}             & \textbf{induction}            & \textbf{coinduction}          \\
    \midrule

    basic activity      & construction          & deconstruction \\
    \midrule

    derived activity    & deconstruction       & construction         \\
    \midrule

    functions shape     & inductive domain     & coinductive codomain \\
    \midrule

    (co)recursive calls& shrinks the argument & grows the result     \\
    \midrule

    functions feature   & terminating          & productive           \\
    \midrule

    evaluation          & possibly eager       & necessarily lazy     \\
    \bottomrule

    \end{tabular}
    \end{center}

    From categorical standpoint, coinduction is formed over a final coalgebra,
    where corecursion is the mediator between any coalgebra into a final one,
    and coinductive proof principle corresponds to the uniqueness of the mediator.
    Recall that coalgebraic effects arises from a particular type of a final
    coalgebra, namely, cofree coalgebra.

    \noindent
    TODO Not sure which paper to cite here for a deeper dive into the upper
    topic. Book \textit{Initial Algebras, Terminal Coalgebras, and the Theory of Fixed Points of Functors}
    by Adámek, Milius and S. Moss from which I have studied is no longer available
    on the internet, as it was a draft under construction.

    Reader that focuses on pragmatism may pose a question, why do we even want
    to reason about infinite structures? They never appear in practice! In fact,
    it's very common to operate on never-ending transition systems or streams of
    data, where finitary means of reasoning are of no use, as we can’t expect
    an end to stream.

    Operating on coinductive structures may involve modification of the internal
    state of the machine that is generating the infinite streams, or in more
    concrete scenario, alternation of the external resource that is providing
    us the data.

    For a better understanding and intuition, we shall illustrate now the
    difference based on inductive and coinductive relation. Recall that the set
    $\Lambda$ of $\mathVar{\lambda-terms}$ is given by the following grammar:

    \begin{center}
        $ e ::= x \;|\; \lambda x.e \;|\; e_{1} e_{2} $
    \end{center}

    \noindent
    where $\Lambda^{0} \subseteq \Lambda$ is a set of $\mathVar{closed~\lambda-terms}$,
    meaning, terms without free variables. Let's now define an inductive,
    and coinductive predicate. Relation
    $\Downarrow{} \subseteq \Lambda^{0} \times \Lambda^{0}$ (convergence) for
    call-by-value $\mathVar{\lambda-calculus}$ is defined as follows:

    \begin{center}
        \AxiomC{}
        \UnaryInfC{$ \lambda x.e \Downarrow{} \lambda x.e $}
        \DisplayProof{}
        \quad\quad
        \AxiomC{$ e_{1} \Downarrow{} \lambda x.e_{0}$}
        \AxiomC{$e_{0}[e_{2}/x] \Downarrow{} e'$}
        \BinaryInfC{$ e_{1} e_{2} \Downarrow{} e' $}
        \DisplayProof{}
    \end{center}

    \noindent
    which means that $ \Downarrow{} $ is the \textit{smallest} predicate
    \textit{closed forward} under the above rules. Relation can be inductively
    built from empty set and then in a fixed-point manner we can add more terms.
    Let's now see a relation $ \Uparrow{} \subseteq \Lambda^{0}$ of
    \textit{divergent} terms, which is coinductively defined as follows:

    \begin{center}
        \AxiomC{$ e_{1} \Uparrow{} $}
        \UnaryInfC{$ e_{1} e_{2} \Uparrow{} $}
        \DisplayProof{}
        \quad\quad
        \AxiomC{$ e_{1} \Downarrow{} \lambda x.e_{0}$}
        \AxiomC{$e_{0}[e_{2}/x] \Uparrow{}$}
        \BinaryInfC{$ e_{1} e_{2} \Uparrow{}$}
        \DisplayProof{}
    \end{center}

    \noindent
    which means that $\Uparrow$ is the \textit{greatest} predicate
    \textit{closed backwards} under the above rules, relation can be coinductively
    obtained by starting with $\Lambda_{0}$, and then by removing elements that
    do not fit the rules.

    \noindent
    For more detailed introduction into coinduction and other examples,
    see~\cite{jacobs-rutten, sangiorgi-intro} or for a deeper
    dive~\cite{sangiorgi-advanced}.

\section{Related Work}
    \subsection{Algebraic Effects}

    Except from Links language~\cite{handlers-cps}, on which the implementation
    is based, there are currently many other alternatives available. One may take
    a look at Frank~\cite{frank}, which provides support for multihandlers,
    Koka~\cite{leijen-koka}, Helium~\cite{helium} or Eff~\cite{eff}. Except from
    separate languages, many libraries arose for existing ones like Haskell,
    Idris, Scala or Multicore OCaml.

    In fact, libraries for algebraic effects also arose in mainstream languages,
    such as C~\cite{leijen-c} or Python~\cite{python-effect}. In Python,
    effects are implemented through generators~\cite{one-shot}, using built-in
    feature of sending value when doing \textit{yield} operation. Resumptions in
    handlers that are sending value are one-shot and tail-recursive.

    As can be seen in the J. Yallop repository~\cite{effects-bibliography}, algebraic
    effects and handlers are now trending branch in the programming languages theory.

    \subsection{Coalgebraic Effects}

    From theoretical side, research on comodels and it's relation to state
    dates to papers by John Power et.\ al.~\cite{comodels, tensors}, and on
    the runners of comodels to T. Uustalu~\cite{runners-uustalu}.

    Practical part that is closest to topic of the thesis, is work done by
    Danel Ahman and Andrej Bauer~\cite{runners-in-action}, as well as their
    implementation of a $\lambda_{coop}$ language~\cite{coop}, which is a
    calculus with runners of coalgebraic effects that ensures linear usage of
    resources as well as execution of code handling finalisation.

\chapter{Potential Solutions}\label{chapter:potential-solutions}

It can be seen, that issues lie with the fact, that interacting with coalgebras
may lead to change of their internal state system. Examples include change of
state in NFA, taking next element in an infinite stream or a closing file.
Finalization must occur after initialization, thus we conclude that resumption
should be called at least once. However, modifying state twice the same way can
also lead to unwanted behaviour, as it was seen in
Section~\ref{sec:problem-statement}, therefore it should be invoked exactly
once.

\begin{lemma}
    Problem of detection whether resumption is called only once is undecidable.
\end{lemma}
\begin{proof}
    Follows directly from Rice's Theorem, as checking whether given function is
    going to be called is a nontrivial semantic property of a program.
\end{proof}

One of the ways to approach this problem, caused by extensive generality of
effects, is the introduction of dual Coalgebraic effects, also named coeffects,
for which we shall discuss various methods of implementation.

\section{Dynamic Constraints Checking}

One approach is to dynamically check against contract that continuation may only
be called once. In this setting we are sure that our program will not accidentally
go into wrong state, however by definition we lack static analysis to prevent
errors before they occur.

\section{Linear Types}

Imposition of a single call of resumption, can be thought in a way that continuation
is `consumable', such that it's not available after one takes use of it. Putting
it in that way, it immediately reminds of linear logic~\cite{linear-logic},
where premises of linear implications are no longer of use in conclusion, and
in case of linear type theory, binding variable from expression A, disallows
use of variables in A. Implementation of coalgebraic effects might be simplified
in languages that already support linear type system, such as Rust~\cite{rust}.

In fact, there is a bijective translation between language with algebraic effects
and calculus with linear type theory, and \textit{every monad embeds in a linear
state monad}~\cite{linear-usage-of-state}.

\noindent
TODO should this section be further extended?

\section{Data-Flow Analysis}

Robust resource management could be also achieved by developing a static
analysis for checking whether resumption is called only once and that
configuration is properly passed.

Data-flow analysis may be the right tool for detecting such anomalies, however,
further work in this area is reserved for future.

\section{Cohandlers as Separate Constructs}

% Simplify semantics by separating coalgebraic effects into a new, restricted
% construct in programming language

Having observed in Section~\ref{sec:duality} that cooperations correspond to
state-passing transitions, we propose a calculus which exactly achieves this
semantic. We divide the solution into three parts, discussed below.

\subsection{State passing}

State passing can be done by embeding given coalgebraic theory in a state monad
over configurations, which in simpler words means, that for a set of coeffects
that we handle, we are going to store current configuration in a state.
Configuration is retrieved before performing a coeffect, and new configuration
is saved after one is handled. Passing of configuration does not leak to the
user, which creates a handy abstraction over operations that manage external
state.

\subsection{Linear usage}

Linear usage of resumptions is not going to be addressed by crafting operational
semantic that ensures that, as in~\cite{runners-in-action}, but rather on a
syntactic level where we verify that resumptions in cohandlers are one-shot and
tail recursive.

\subsection{Combining effects with coeffects}

Despite of the above means, algebraic effects that occur in the source code may
drop the resumption and thus finalization code is not going to be executed.
We address this issue by not allowing effects to escape the cohandler, which
means that we are not going to discard the execution of cohandler.


\chapter{(Co)Effectful Programming}\label{chapter:co-effectful-programming}
\section{Examples}\label{sec:examples}

    In this section we present a few examples to show the capabilities of the language.
    The ideas have been based on~\cite{programming-in-eff}, and thus will not be
    described in great details. More exemplary programs in Freak language can
    be found in \verb!src/programs! directory~\cite{freak}.

    \subsection{Choice}\label{sec:choice-example}

    The first example will be based on modelling (nondeterministic) choice
    in the program. We will make two decisions, which will affect the computation
    result:

\begin{verbatim}
    let c1 <- do Choice () in
    let c2 <- do Choice () in
    let x <- if c1 then return 10 else return 20 in
    let y <- if c2 then return 0 else return 5 in
    return x - y
\end{verbatim}
    With that in hand, we may want to define effect handlers:

\begin{verbatim}
    handle ... with {
        Choice p r ->
            let t <- r 1 in
            let f <- r 0 in
            <PLACEHOLDER> |
        return x -> return x
    }
\end{verbatim}
    where in the \verb!<PLACEHOLDER>! we can define what to do with the
    computation. For example, min-max strategy for picking the minimum value:

\begin{verbatim}
    if t < f then return t else return f
\end{verbatim}
    where the code evaluates to \verb!5!. Another example is a handler that
    collects all possible results, which can be achieved by putting
    \verb!return (t, f)! in the \verb!<PLACEHOLDER>!, which evaluates to
    \verb!((10, 5), (20, 15))!.

    \subsection{Exceptions}

    Exceptions are simply algebraic effect handlers which drop the resumption.

\begin{verbatim}
    handle
        if x == 0 then do ZeroDivisionError ()
                  else return 1/x
    with {
        ZeroDivisionError p r -> return 42 |
        return x -> return x
    }
\end{verbatim}
    Where we imagine that $x$ variable has been bound previously.

    \subsection{Taming Side effects}

    The complexity of the programs and their performance usually comes from side effects.
    Algebraic effects allow us to define code in a declarative manner, and hence
    neatly tame the side effects that they produce. This gives us a lot of flexibility
    in the actual meaning without duplicating the code. Let's consider the following
    very basic code snippet:

\begin{verbatim}
    let x <- do Fetch () in
    -- operate on x
\end{verbatim}

    The code is dependent on a context in which it is executed, which here is
    the handler that defines the behaviour of the algebraic \verb!Fetch! effect.
    In the imperative, or even functional approach, we would need to provide
    the interface for fetching the data by doing dependency injection or even
    embedding the operation directly. Here we are just stating what operation
    we are performing, leaving the interpretation up to the execution context,
    which could do the fetching or mock the external resource.

    These implications are straightforward when looking from a categorical standpoint,
    where effects are viewed as free models of algebraic theories~\cite{adequacy},
    and handlers are homomorphisms preserving the model structure~\cite{handlers}.
    Nevertheless, the results are very exciting for programming use cases.

\section{Coexamples}

    TODO Introduction into coeffects from Freak side

    \subsection{File handling}

    The first example we are going to show is file handling. As per
    Section~\ref{sec:problem-statement}, we do not want to expose file handle
    to the user, thus we hide it behind carrier of FileIO coalgebraic theory,
    for which the signature is composed of Open, Write and Close operations.

\begin{verbatim}
    cohandle FileIO using "filename.txt" at
        let _ <- observe Open () in
        let _ <- observe Write "Karma Chameleon" in
        let _ <- observe Close () in
        return 42
    through {
        Open p r ->
            let filename <- return fst p in
            let fh <- do OpenBI filename in
            r (fh, ()) |
        Write p r ->
            let fh <- return fst p in
            let _ <- do WriteBI fh in
            r (fh, ()) |
        Close p r ->
            let fh <- return fst p in
            let _ <- do CloseBI fh in
            r ((), ()) |
        return x -> return x
    }
\end{verbatim}

    In the above code, we initialize the coalgebra carrier with filename that
    we want to handle, we open file, write to it once and then close it. Notice
    that file handle is not present in the user code, but only accessible in
    the runner of FileIO as a first element of a pair.

    \subsection{Nondeterministic Finite Automata}

    This example shows how one can implement NFA using coeffects. We abstract
    over internal state of the automata, and based on letters from the alphabet,
    we change automata configuration and return whether word is accepted or not.
    The code below returns whether given NFA accepts word "abba".

\begin{verbatim}
    cohandle Automata using 0 at
        let _ <- observe NFA a in
        let _ <- observe NFA b in
        let _ <- observe NFA b in
        observe NFA a
    through {
        NFA p r ->
            let state <- return fst p in
            let letter <- return snd p in
            <code transitions here> |
        return x -> return x
    }
\end{verbatim}

\section{Usage guide}

    % Outdated
    As of this day, two implementations are available, one based on the curried
    translation from Appel~\cite{appel-continuations}, and the second one based
    directly on the uncurried translation with continuations as explicit
    stacks~\cite{handlers-cps-journal}. More details can be found in
    Section~\ref{chapter:implementation}. All commands are available within the
    \verb!src! directory.

    \subsection{Build and install}

    \begin{itemize}
        \item Install dependencies: \verb!make install!
        \item Select implementation: \verb!make link-lists! (default) vs \verb!make link-appel!
        \item Compile: \verb!make build!
        \item Link to PATH:~\verb!sudo make link!
        \item Remove artifacts: \verb!make clean!
    \end{itemize}

    After compiling and linking program to PATH, one may evaluate program as
    follows: \verb!freak programs/choicesList.fk! The actual code is described in Section~\ref{sec:choice-example}

    \subsection{Running tests}

    Test cases are available \href{https://github.com/Tomatosoup97/freak/blob/master/src/Tests.hs}{\underline{here}},
    they include both inline and file-based tests. For more details about
    writing tests, one may refer to \textit{HUnit documentation}~\cite{hunit-docs}.

    \begin{itemize}
        \item Run tests: \verb!make tests!
        \item Run code linter: \verb!make lint!
        \item Compile, run linter and tests: \verb!make check!
    \end{itemize}

\chapter{Calculus of Freak language}\label{chapter:calculus-of-freak-language}
\section{Syntax}

    The syntax for the calculus is shown below. $nat \; n$ represents an integer $n$,
    `string' a string value, $V \oplus W$ and $V \approx W$ are respectively
    binary and relational operators, where we support basic arithmetic and
    comparison operations. \textbf{if} $V$ \textbf{then} $M$ \textbf{else} $N$
    is a standard branching statement. The other constructs are just as in
    Links~\cite{handlers-cps-journal}, with slight syntax modifications.
    Actual programs in Freak can be found in Section~\ref{sec:examples}.

    TODO cohandlers

    % TODO proper alignment
    \begin{grammar}

        <Values V, W> $::=$ $ x $ \\
            | $nat \; n$ | `string'  \\
            | $ \backslash x : A \rightarrow M $ | \textbf{rec} $ g \; x \rightarrow M $\\
            | $V \oplus W$ | $V \approx W$ \\
            | <> | $ \{ \ell = V; W\} $  | ${[ \ell \; V]}^{R}$

        <Computations M, N> $::=$ $ V $ $ W $ \\
            | \textbf{if} $V$ \textbf{then} $M$ \textbf{else} $N$ \\
            | \textbf{let} $\{\ell  = x; y\} = V$ \textbf{in} $ N $ \\
            | \textbf{case} $V \{ \ell \; x \rightarrow M; y \rightarrow N\}$ | \textbf{absurd} $ V $ \\
            | \textbf{return} $V$ | \textbf{let} $ x \leftarrow M $ \textbf{in} $ N $ \\
            | \textbf{do} $\ell \; V$ | \textbf{handle} $M$ \textbf{with} $ \{ H \} $

        <Handlers H> $::=$ \textbf{return} $ x \rightarrow M $ | $ \ell \; p \; r \rightarrow M, H $

        <Binary operators $\oplus$> $::=$ + | $-$ | * | /

        <Relational operators $\approx$> $::=$ $ \textless $ | $\leqslant$ | $>$ | $\geqslant$ | == | $!= $

    \end{grammar}

\section{Dynamics}

    Semantic of Freak is heavily based on Links langauge~\cite{handlers-cps-journal},
    for which the source language's dynamics have been described extensively by
    providing small-step operational semantics, continuation passing style
    transformation~\cite{handlers-cps} as well as abstract
    machine~\cite{liberating-effects}, which was proved to coincide with CPS
    translation. That being said, Freak introduces new basic constructs to the
    language, for which we shall define the semantics.

    \noindent
    Extension of the evaluation contexts:

    \noindent
    $\mathcal{E} ::= \mathcal{E} \oplus W \; | \; nat \; n \oplus \mathcal{E} \; |$ \textbf{if} $\mathcal{E}$ \textbf{then} $M$ \textbf{else} $N$

    \noindent
    Small-step operational semantics:

    \noindent
    \textbf{if} $nat \; n$ \textbf{then} $M$ \textbf{else} $N \rightsquigarrow M \quad \quad $ if $n \neq 0$ \\
    \textbf{if} $nat \; n$ \textbf{then} $M$ \textbf{else} $N \rightsquigarrow N \quad \quad $ if $n = 0$

    \noindent
    $nat \; n \oplus nat \; n' \rightsquigarrow n'' \quad \quad $    if $ n'' = n \oplus n' $ \\
    $nat \; n \approx nat \; n' \rightsquigarrow 1  \quad \quad $    \; if $ n \approx n' $ \\
    $nat \; n \approx nat \; n' \rightsquigarrow 0  \quad \quad $    \; if $ n \not\approx n' $

    TODO cohandlers

\chapter{Implementation}\label{chapter:implementation}

    The Freak implementation is available on github~\cite{freak}, written purely
    in Haskell. Two inherently different takes at implementations were made. The
    first one is based on curried translation from A. Appel~\cite{appel-continuations}
    book, and the second one on Links language~\cite{handlers-cps, handlers-cps-journal},
    on the uncurried translation to target calculus with continuations represented
    as explicit stacks. We start by presenting core data structures, and
    afterwards move to actual translation details. Development of the former
    Appel's version is now suspended.

    \section{Abstract Syntax Tree}\label{sec:implementation-ast}

    The language's AST is defined without surprises, just as syntax is:

\begin{verbatim}
    data Value
        = VVar Var
        | VNum Integer
        | VStr String
        | VLambda Var ValueType Comp
        | VFix Var Var Comp
        | VUnit
        | VPair Value Value
        | VRecordRow (RecordRow Value)
        | VExtendRow Label Value Value
        | VVariantRow (VariantRow Value)
        | VBinOp BinaryOp Value Value

    data Comp
        = EVal Value
        | ELet Var Comp Comp
        | EApp Value Value
        | ESplit Label Var Var Value Comp
        | ECase Value Label Var Comp Var Comp
        | EReturn Value
        | EAbsurd Value
        | EIf Value Comp Comp
        -- Algebraic effects
        | EOp Label Value
        | EHandle Comp Handler
        -- Coalgebraic effects
        | ECoop Label Value
        | ECohandle Comp Handler
\end{verbatim}

    \noindent
    Similarly for the target calculus data structure. However, as one may notice,
    for convenience the \textbf{let} translation is homomorphic, as opposed to be
    to lambda abstracted with immediate application:

\begin{verbatim}
    data UValue
        = UVar Var
        | UNum Integer
        | UStr String
        | UBool Bool
        | ULambda Var UComp
        | UUnit
        | UPair UValue UValue
        | ULabel Label
        | URec Var Var UComp
        | UBinOp BinaryOp UValue UValue

    data UComp
        = UVal UValue
        | UApp UComp UComp
        | USplit Label Var Var UValue UComp
        | UCase UValue Label UComp Var UComp
        | UIf UValue UComp UComp
        | ULet Var UComp UComp
        | UAbsurd UValue
        | UTopLevelEffect Label UValue
\end{verbatim}

    \noindent
    The final answer, common to both evaluations, is represented as a \verb!DValue!,
    where the meaning of the coproduct is as one would expect:

\begin{verbatim}
    type Label = String

    type FuncRecord = [DValue] -> Either Error DValue

    data DValue
        = DNum Integer
        | DStr String
        | DLambda FuncRecord
        | DUnit
        | DPair DValue DValue
        | DLabel Label
\end{verbatim}

    \noindent
    Evaluation of target calculus is typical to call-by-value with syntactic
    distinction between values and computations. For more details, refer
    to~\cite{handlers-cps-journal}. That being said, there is one part
    that requires more attention, namely, \verb!UTopLevelEffect Label UValue!,
    which represents an unhandled algebraic effect along with it's parameter.
    Even in case language has coalgebraic effects, special treatment is required
    for doing IO\@. For that reason, we define default handling for a few effects
    for printing to console and handling files, where semantic is just as one
    would expect from naming. We abuse haskell's notation to define types for
    algebraic effects living in Freak langauge:

\begin{verbatim}
    type Filename = String
    Print :: String -> ()
    ReadLine :: () -> String
    ReadFile :: Filename -> String
    WriteFile :: (Filename, String) -> ()
    AppendFile :: (Filename, String) -> ()
\end{verbatim}

    \section{Curried translation}

    The first take was heavily inspired by A. Appel's Compiling with
    Continuations~\cite{appel-continuations}, which provides a translation for
    a simplified ML calculus. The calculus was extended and translation adapted to
    handle algebraic effects and their handlers. The translation is based on the curried
    first-order translation. That being said, the source code diverged a lot from the
    paper on which it was based, leading to a different transformation for which the
    correctness and cohesion with operational semantics should be proved separately.
    Indeed, while the interpreter worked well on the use cases defined in tests, the
    evaluation had a part which was not tail-recursive. What's more, nested handlers
    were not supported, and the implementation was found to be trickier than it should,
    as it was not obvious on how to adopt the technique proposed in the paper.

    In terms of improving the performance of the evaluation, uncurried higher-order
    translation should be adapted, so that administrative redexes are contracted
    and proper tail-recursion is obtained. The core data structure, into which the
    source program is transformed, is defined as follows:

\begin{verbatim}
    data ContComp
        = CPSApp CValue [CValue]
        | CPSResume CValue ContComp
        | CPSFix Var [Var] ContComp ContComp
        | CPSBinOp BinaryOp CValue CValue Var ContComp
        | CPSValue CValue
        | CPSLet Var CValue ContComp
        | CPSSplit Label Var Var CValue ContComp
        | CPSCase CValue Label Var ContComp Var ContComp
        | CPSIf CValue ContComp ContComp
        | CPSAbsurd CValue
\end{verbatim}
    Most of the terms at the end have a coinductive reference to itself, which
    represents the rest of the computation that needs to be done. For more
    clarification, one may take a look into the book mentioned
    above~\cite{appel-continuations}. The source code for curried translation and
    evaluation can be found respectively in \verb!CPSAppel.hs! and
    \verb!EvalCPS.hs!. Development of this version of translation is discontinued.

    \section{Uncurried translation}

    Having in mind the drawbacks mentioned above, alternative translation was
    written, that coincides with the translation from~\cite{handlers-cps-journal}.
    Namely, with the uncurried translation to target calculus with continuations
    represented as explicit stacks. The target calculus was described in
    Section~\ref{sec:implementation-ast}. The continuations are represented as
    \verb!Cont!, with syntactic distinction between pure, effectful and
    coeffectful computations. Pure and (co)effectful continuations occupy
    alternating positions in the stack. Explicit distinction was made to provide
    more control in the source code.

\begin{verbatim}
    type CPSMonad a = ExceptT Error (StateT Int IO) a

    type ContF = UValue -> [Cont] -> CPSMonad UComp

    data Cont = Pure ContF
              | Eff ContF
              | Coeff ContF
\end{verbatim}

    \noindent
    Where \verb!CPSMonad! is a monad transformer over \verb!Either!, \verb!State!
    and \verb!IO!. \verb!State! is required to generate labels for fresh variables
    that came from the translation, \verb!Either! for handling exceptions that
    may occur during translations, and \verb!IO! for handling input output of the
    source language.

\begin{verbatim}
    initialPureCont :: ContF
    initialPureCont v ks = (return . UVal) v

    initialEffCont :: ContF
    initialEffCont (UPair (ULabel effLabel) (UPair p r)) ks =
        return . UApp (UVal r) $ UTopLevelEffect effLabel p

    initialContStack :: [Cont]
    initialContStack = [Pure initialPureCont, Eff initialEffCont]
\end{verbatim}

    \noindent
    Initial pure continuation is lifting values into computations,
    and effectful one is propagating previously mentioned \verb!UTopLevelEffect!.
    Notice that \verb!initialContStack! does not have initial cohandler,
    as handling of default coeffects is embed in evaluator. The core code is
    split into a few functions:

\begin{verbatim}
cps     :: Comp    -> [Cont] -> CPSMonad UComp
cpsVal  :: Value   -> [Cont] -> CPSMonad UValue
cpsOp   :: Label -> Value -> [Cont] -> CPSMonad UComp
cpsHRet :: Handler -> Cont
cpsHOps :: (ContF -> Cont) -> Handler -> Cont
forward :: Label   -> UValue -> UValue -> [Cont] -> CPSMonad UComp
runCPS  :: Comp -> EvalResMonad UComp
\end{verbatim}

    \noindent
    Where the first two are implementing cps for computations and values.
    \verb!cpsOp! is doing translation for an (co)effect that occured in program,
    \verb!cpsHRet! and \verb!cpsHOps! are yielding pure and effectful continuations,
    based on a given handler. \verb!forward! is responsible for forwarding the
    computation to the outer handler, and the last one for running the
    translation, where evaluation result is represented by\\
    \verb!type EvalResMonad a = IO (Either Error a)!. This results in an
    implementation that finally supports nested handlers, which can be seen by
    running tests. Links language~\cite{handlers-cps-journal} also supports
    shallow handlers~\cite{shallow-handlers}, whereas our langauge implements
    only deep ones.

    \section{Cohandlers}
    \ldots

    \section{Source Code Structure}

    The source code is divided into a number of modules, where the most
    crucial parts have already been described.

\begin{verbatim}
    AST.hs          - AST data structures
    CommonCPS.hs    - Common functions for CPS translation
    CommonEval.hs   - Common functions for evaluation
    CPSLists.hs     - Uncurried CPS translation
    EvalTarget.hs   - Evaluation of the target calculus
    Freak.hs        - API for the language
    Main.hs         - Main module running evaluator on given filename
    Parser.hs       - Parser and lexer
    TargetAST.hs    - AST for the target calculus
    Tests.hs        - Tests module
    Types.hs        - Common types definition
    programs/       - Exemplary programs covered in tests

    CPSAppel.hs     - [deprecated] Appel-based CPS translation
    EvalCPS.hs      - [deprecated] Evaluation of the Appel's CPS structure
\end{verbatim}

\chapter{Conclusion}\label{chapter:conclusion}
\section{Summary}

    TODO What was achieved, what was described, what needs to be done or researched.

\section{Future work}

    \subsection{Abstract machine}

    The Links language, on which CPS translation Freak was based, also provides
    small-step operational semantics~\cite{handlers-cps} and an abstract
    machine~\cite{liberating-effects}. Implementing another way of evaluation
    could serve as a way to empirically assert correctness, as opposed to formally.
    Abstract machine would need to be extended to incorporate coeffects.

    \subsection{Type inference and row polymorphism}

    The type system as of this day is not implemented, as the focus has been put
    on CPS transformation and dynamics of the calculus with effects and coeffects.
    Further work is required here, especially considering the fact that a huge
    advantage of algebraic effects is that they are explicitly defined in the
    type of a computation.

    \subsection{Multiple instances of algebraic effects}

    The Freak language is limited to a single instance of an effect. We would
    need to support cases where many instances of the algebraic effects, with
    the same handler code, could be instantiated. The current state of the
    art introduces a concept of resources and instances, as in Eff~\cite{programming-in-eff},
    or instance variables, as in Helium~\cite{binders-labels}. Another part is
    to research on how this area combines with coalgebraic part.

    \subsection{Selective CPS}

    Other languages, like Koka~\cite{leijen-koka}, or even the core of the Links,
    are performing selective CPS translation, which reduces the overhead on code
    that does not perform algebraic effects. Our current translation is fully
    embedded in CPS transformation.

    \subsection{Exceptions and signals}

    Exceptions are a trivial example of algebraic effect where the resumption is
    discarded, and as described in \S 4.5~\cite{handlers-cps}, they can be modeled
    as a separate construct to improve performance.

    \subsection{Shallow handlers}

    Shallow and deep handlers while being able to simulate each other up to
    administrative reductions, have a very different meaning from a theoretical point
    of view. Implementing them as defined by Lindley et al.~\cite{shallow-handlers}
    could be another way of enhancing Freak.


%%%%% BIBLIOGRAPHY

\printbibliography{}

\end{document}
